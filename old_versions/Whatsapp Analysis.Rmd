---
title: "R Whatsapp Analysis"
output: html_notebook
---

This code sets out how to upload and then analyse Whatsapp text data using both charts and networks.

```{r}

library("RCurl")
library("data.table")
library(stringr)

#tab = read.delim(getURL("https://raw.githubusercontent.com/robert-sturrock/whatsapp-analysis/master/chat.txt"))
#write.table(tab, file="text.csv",sep=",",col.names=FALSE,row.names=FALSE)



chat <- read.table("C:/Users/rober/Desktop/chat.txt",  fill=TRUE, quote="", sep="\n", encoding="UTF-8")
names(chat) <- "string"

```

Now we need to look at the data and format it approperiately 

```{r}
head(chat)

```

So we can see we have a date, time, sender, and message. 

The first obvious issue here is that one of the senders names has been messed up. We can fix this using the regex commands in R 

```{r}

chat$string <- gsub("+1 (215) .*: ", "Debbie Blair: ", chat$string )
head(chat$string)




```

Now that we have made that correction we need to split the string of text into the individual components identified above: 

```{r}
library(tidyverse)

regx <- "(\\d+/\\d+/\\d+),\\s+(\\d+:\\d+:\\d+ [A|P]M):\\s+(\\w+\\s*\\w+):\\s+(.*)"

tmp <- chat %>% 
    tidyr::extract(string, c("date", "time", "sender", "message"), regx, remove=FALSE)


#eliminate NA rows (for now)
tmp <- filter(tmp, !is.na(sender))

```

We now have our desired variables. Lets build some basic functionality like search

```{r}

#regular expression search
grep("sex", tmp$message, value=TRUE)


#function that returns other columns of the data as well
text_search <- function(text, df){
  tmp <- df
  tmp_index <- grep(text, tmp$message)
  tmp[c(tmp_index),c("sender", "message")]
}

text_search("sex", tmp)

#function to search around a specific instance (message before and after)

# this function generates another function that allows the user to select which instance of a word, and the 
# number of lines around that word, they want to see. 

conv_search <- function(text, df){ 
  tmp <- df
  tmp_index <- grep(text, tmp$message)
  
  #return lines
  index <- tmp_index
  
  function(instance, num_lines){
    if (num_lines %% 2 !=0){"error, needs even number"} else {
    
    instance <- index[instance]
    start <- instance - num_lines/2
    end   <- instance + num_lines/2  
    tmp[start:end, c("sender", "message")]
    } 
  }
  
  
}

sex_search <- conv_search("sex", tmp)
sex_search(2,6)

library(wordcloud)


```



Great. So we built some functions that make it easy to search text. 

But searching isn't really the best way to get data about what people talked about. Charts on the other hand are awesome. 

I start by building a simple frequency chart of how often a given work was said


```{r}

# Create a single block of text with all the words

test <- unlist(tmp$message[tmp$sender == "Liam Kirwin"])
test <- unlist(tmp$message)
test <- paste(test, sep="",collapse =" ")

# load required packages

library(tm)
library(dplyr)
library(xtable)

docs <- Corpus(VectorSource(test)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(tolower)  %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stripWhitespace) %>%
  tm_map(PlainTextDocument)

tdm <- TermDocumentMatrix(docs) %>%
  as.matrix()

tdm <- as.matrix(tdm[,1])
tdm <- as.matrix(tdm[order(tdm, decreasing = TRUE),])
#tdm <- as.matrix(tdm[10:17546,])
#tdm <- tdm[order(tdm, decreasing = TRUE),]



wordcloud(row.names(tdm), tdm, min.freq = 35, scale=c(5, .2), random.order = FALSE, random.color = FALSE, colors= c("indianred1","indianred2","indianred3","indianred"))




#Now we create a wordcloud function 

WA_wordcloud <- function(sender, df, min.freq){
  
  #required packages
  #require(tm)
  #require(dplyr)
  #require(xtable)
  #require(wordcloud)
  #require(stringr)
  
  #set function
  tmp <- unlist(df$message[df$sender == sender])
  tmp <- paste(tmp, sep="",collapse ="")
  
  #eliminate all non alpha numberic
  tmp <- str_replace_all(tmp, "[^a-zA-Z0-9]"," ")

  
  #create term document matrix and format it
  tmp_docs <- Corpus(VectorSource(tmp)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(tolower)  %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removeWords,"image") %>%
  tm_map(stripWhitespace) %>%
  tm_map(PlainTextDocument)
  
  tmp_tdm <- TermDocumentMatrix(tmp_docs) %>%
  as.matrix()
  
  tmp_tdm <- as.matrix(tmp_tdm[,1])
  tmp_tdm <- as.matrix(tmp_tdm[order(tmp_tdm, decreasing = TRUE),])
  
  #create wordcloud
  layout(matrix(c(1,2), nrow = 2), heights = c(1,2))
  par(mar = rep(0,4))
  plot.new()
  text(x=0.5, y=0.5, sender)
  
  
  wordcloud(row.names(tmp_tdm), tmp_tdm, 
            min.freq = min.freq, 
            scale=c(2, .1), 
            random.order = FALSE, 
            random.color = FALSE,  
            colors= c("indianred1","indianred2","indianred3","indianred"))


  
}


WA_wordcloud(sender = "Liam Kirwin", df = tmp, min.freq = 15)

flat_names <- list("Liam Kirwin", "Isabel Lachenauer", "Robert", "Debbie Blair", "Elizabeth Stone")

lapply(flat_names, function(x) WA_wordcloud(x, df = tmp, min.freq = 25))

```


Another potentially interesting idea is to do a wordcloud of words that people use more than the average. This would involve calculating two data.frames/matricies with words and frequencies. And then subtracting the individual words from the average. 


Step 1: 
```{r}

#create a function that creates a tdm 

tdm_creator <- function(sender="all", df){
  
  #set function
  if(sender != "all"){tmp <- unlist(df$message[df$sender == sender])} else {tmp <- unlist(df$message)}
  tmp <- paste(tmp, sep="",collapse ="")
  
  #eliminate all non alpha numberic
  tmp <- str_replace_all(tmp, "[^a-zA-Z0-9]"," ")

  
  #create term document matrix and format it
  tmp_docs <- Corpus(VectorSource(tmp)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(tolower)  %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removeWords,"image") %>%
  tm_map(stripWhitespace) %>%
  tm_map(PlainTextDocument)
  
  tmp_tdm <- TermDocumentMatrix(tmp_docs) %>%
  as.matrix()
  
  tmp_tdm <- as.matrix(tmp_tdm[,1])
  as.matrix(tmp_tdm[order(tmp_tdm, decreasing = TRUE),])
}



word_df <- function(matr){
  data.frame(word = row.names(matr), freq = matr)
}

#create data.frames to compare
isabel <- tdm_creator(sender = "Isabel Lachenauer", df = tmp)
liam <- tdm_creator(sender = "Liam Kirwin", df = tmp)
all <- tdm_creator(df = tmp)

isabel <- word_df(isabel)
liam <- word_df(liam)
all <- word_df(all)

t <- left_join(liam, all, by = "word")
t <- left_join(isabel, all, by = "word")

#identify words that liam says relatively more than others

t$diff <- t$freq.x - t$freq.y/5


t %>% arrange(desc(diff)) %>% head()

#control also for frequency that the word appears in the general group chat 

t <- t[t$freq.x <= t$freq.y,]
t$diff2 <- (t$freq.x - t$freq.y/5)/t$freq.y


t %>% arrange(desc(diff2)) %>% head()

#create a word cloud of most unique words

t2 <- t %>% filter(diff>0)

wordcloud(t2$word, t2$diff,
            scale=c(3, .1), 
            random.order = FALSE, 
            random.color = FALSE,  
            colors= c("indianred1","indianred2","indianred3","indianred"))

# use alternative method, but only use words that appear at least 3 times
t3 <- t %>% filter(diff2>0 & freq.x >3)


wordcloud(t3$word, t3$diff2,
            scale=c(3, .1), 
            max.word = 100,
            random.order = FALSE, 
            random.color = FALSE,  
            colors= c("indianred1","indianred2","indianred3","indianred"))

```



```{r}

# Function that creates a unique word cloud by person 

unique_wordcloud <- function(df, sender, type){
  
  #total senders
  tot_senders <- length(unique(df$sender))
  
  #create tdm
  person <- word_df(tdm_creator(sender = sender, df = tmp))
  all <- word_df(tdm_creator(df = tmp))
  
  t <- left_join(person, all, by = "word")

  #identify words that liam says relatively more than others
  
  t$diff <- t$freq.x - t$freq.y/tot_senders
  
  #control also for frequency that the word appears in the general group chat 
  
  t <- t[t$freq.x <= t$freq.y,]
  t$diff2 <- (t$freq.x - t$freq.y/tot_senders)/t$freq.y
  
  #create a word cloud of most unique words
  
  t2 <- t %>% filter(diff>0)
  t3 <- t %>% filter(diff2>0 & freq.x >3)

  
  
  if (type == 1){
  wordcloud(t2$word, t2$diff,
              scale=c(3, .1), 
              random.order = FALSE, 
              random.color = FALSE,  
              colors= c("indianred1","indianred2","indianred3","indianred"))} 
  
  else if (type ==2){
  wordcloud(t3$word, t3$diff2,
            scale=c(3, .1), 
            random.order = FALSE, 
            random.color = FALSE,  
            colors= c("indianred1","indianred2","indianred3","indianred"))
  } else {stop('invalid type selected')}
  
    
  
}

unique_wordcloud(df = tmp, sender = "Elizabeth Stone", type = 2)
unique_wordcloud(df = tmp, sender = "Robert", type = 2)






flat_names <- list("Liam Kirwin", "Isabel Lachenauer", "Robert", "Debbie Blair", "Elizabeth Stone")

lapply(flat_names, function(x) unique_wordcloud(sender = x, df = tmp, type = 2))


```

# Words said over time

So now I need to replicate some of the work I did earlier, namely plotting the frequency of words over time


```{r}


#step 1:

#count the number of times a word appears by date
tmp %>% group_by(date) %>% summarise(number = n())






```


#who talks to who the most


```{r}



#write a function that looks at most frequent reponders


response_summary <- function(df, person, type){
library(scales)
#select sender 
  tmp <- df 
  tmp$indicator <- 0 
  tmp[tmp$sender == person,]$indicator <- 1 
  tmp$ind <- lag(tmp$indicator)

  #calculate total messages by sender 
  tmp <- tmp %>% group_by(sender) %>%
  mutate(total_messages = n()) 
  tmp
  
  #create statistics
  if (type == 1){ tmp %>% group_by(sender) %>% 
      filter(ind == 1) %>% 
      summarise(total_responses = n())
  
  } else if (type == 2){ tmp %>% group_by(sender) %>% 
      filter(ind == 1) %>% 
      mutate(total_responses_to_sender = n()) %>% 
      mutate(done = total_responses_to_sender/total_messages) %>% 
      summarise("% of all messages made in response to sender" = percent(mean(done)))} }


response_summary(tmp, "Liam Kirwin", type = 1)


# Create a response matrix


response_matrix <- function(df, type){

senders <- response_summary(tmp, flat_names[[1]], type = type)$sender


responses_total <- cbind(as.data.frame(lapply(senders, function(x)
response_summary(df, x, type = type)[[2]]))) 
names(responses_total) <- senders 
row.names(responses_total) <- senders 
responses_total


}

response_matrix(tmp, 1)

#check how equally people respond to each other

mat1 <- as.matrix(response_matrix(tmp, 1)) # how often x responded to y 
mat2 <- t(mat1) # how often y responded to x

#so what this means is that mat1[1,2] - mat2[1,2] is how often Lizzie replied to  Debbie - how often Debbie replied to Lizzie

mat1 
mat2

# the results show that people in our conversation are quite equal. Which is what we'd expect in conversations where two people are most important/no one person is avoiding the other.

(mat1 - mat2)


# total messages people sent

lapply(response_matrix(tmp,1), sum)

# do this by word count 
```





# Duplicate the functions above, but apply it to individual words


```{r}



#write a function that looks at most frequent reponders


response_summary_word <- function(df, person, type, word){
library(scales)
library(magrittr)
#select sender 
  tmp <- df 
  tmp$indicator <- 0 
  if (length(tmp[tmp$sender == person & grepl(word, tmp$message),]$indicator) > 0){
    tmp[tmp$sender == person & grepl(word, tmp$message),]$indicator <- 1 
  } else { 
    tmp$indicator <- 0
  }
  tmp$indicator <- lag(tmp$indicator)
  tmp %<>% mutate(indicator = ifelse(is.na(indicator), 0, indicator))

#calculate total messages by sender 
  tmp <- tmp %>% group_by(sender) %>%
    mutate(total_messages = n()) 
  

if (type == 1){ tmp %>% group_by(sender) %>% summarise(total_responses = sum(na.omit(indicator)))

} else if (type == 2){tmp %>% group_by(sender) %>%
    mutate(total_responses_to_sender = sum(na.omit(indicator))) %>%
    mutate(done = total_responses_to_sender/total_messages) %>% 
    summarise("% of all messages made in response to sender" = percent(mean(done)))} }



response_summary_word(tmp, "Robert", type = 1, word="sex")






# Create a response matrix


response_matrix_word <- function(df, type, word){
senders <- response_summary(df, df$sender[[1]], type = 1)$sender


responses_total <- cbind(as.data.frame(lapply(senders, function(x)
response_summary_word(df, x, type = type, word = word)[,2]))) 
names(responses_total) <- senders 
row.names(responses_total) <- senders 
responses_total


}

response_matrix_word(tmp, 1, word = "lol")



```





# Next: write some of the functions using SE

```{r}

library(lubridate)

#select groups usinge SE

freq_plot <- function(df, word, v1, v2){

 df %>% mutate(date = mdy(date)) %>%
  group_by_(v1, v2) %>%
  filter(grepl(word, message)) %>%  
  summarise(count = n()) %>%
  ggplot(aes(x = date, y = count, color = sender)) + geom_point() + ylim(0,NA) + theme_bw() }


freq_plot(tmp, ".", v1 = "sender", v2 = "date")

#summary table of two variable

tw_tab <- function(df, v1, v2){

tmp <- df

tmp %>% group_by_(v1, v2) %>% 
  mutate(tot=n()) %>% 
  ungroup() %>% 
  group_by_(v1) %>% 
  mutate(perc = tot/n()) %>% 
  ungroup() %>% group_by_(v1, v2) %>% 
  summarise(end = mean(perc)) %>% dcast(paste(v1, '~', v2), value.var = "end")

}

# plot share of conversation over time 
tw_tab(tmp, "date", "sender") %>%
  mutate(date = mdy(date)) %>% 
  melt(id.vars="date") %>% 
  ggplot(aes(x = date, y = value, color = variable, fill = variable)) + geom_col()




```








# Next: turn the response matrix into a network diagram

In order to do this I basically want to depict the relationships between people
and how important people are to the conversation.

Features include:

* nodes that are sized based on number of messages a person sent * directional
flows that are related to number of messages sent * do this for individual words


```{r}

library(visNetwork) 
library(igraph)


# Create nodes data.frame

library(dplyr) 
library(magrittr)

# create names
nodes <- data.frame(select(tmp, sender) %>% distinct()) 
names(nodes) <- "id"


# create number of messages sent 
totals <- select(tmp, sender) %>%
  group_by(sender) %>% 
  summarise(sum = n()) 

nodes$size <- (totals$sum *100)/sum(totals$sum)
# Create edges of data.frame 

responses <- response_matrix(tmp, 1) 

responses <-as.data.frame(responses)
responses$name <- row.names(responses) 
responses_m <- melt(responses) 
names(responses_m) <- c("from","to", "number")

# format as network

edges <- responses_m 
edges$to <- as.character(edges$to) 
edges$width <- (edges$number * 100)/sum(totals$sum)
edges$title <- paste("<p style=\"color:black\">",edges$number,"</p>")

# add in node colors, names 
nodes$group <- nodes$id 
nodes$label <- nodes$id 
nodes$title <- paste("<p style=\"color: black\">",totals$sum,"</p>")

# plot library(visNetwork) 
visNetwork(nodes, edges, width = "100%") %>%
visPhysics( solver ='forceAtlas2Based')




```










# New additions:

* do analysis of messages by number of words (done)
* do network and table for an individual word (table done)
* topic analysis 
* build app that allows you to upload file to analyse (produces network and word clouds)


# Count number of words

```{r}

# Create variable that is number of words per message

test <- "this message has many words in it"
length(unlist(strsplit(test, split = " ")))

test2 <- data.frame(c = c("message with three", "message with two"), stringsAsFactors = FALSE)
str(test2)
length(unlist(strsplit(test2$c, split = " ")))


library(stringr)

# create variable with number of words in each line

tmp %<>% ungroup
tmp %>% mutate(number_words = str_count(message, " ")) %>% group_by(sender) %>% summarise(total_words = sum(number_words), avg_message_length = total_words/mean(total_messages))



```


# Word sepecific matrix


```{r}

library(visNetwork) 
library(igraph)


# Create nodes data.frame

library(dplyr) 
library(magrittr)

# create names
nodes <- data.frame(select(tmp, sender) %>% distinct()) 
names(nodes) <- "id"


# create number of messages sent 
totals <- select(tmp, sender, message) %>% 
  group_by(sender) %>% 
  summarise(sum = n()) 

nodes$size <- (totals$sum *100)/sum(totals$sum)
# Create edges of data.frame 

responses <- response_matrix_word(tmp, 1, word = "sex") 

responses <-as.data.frame(responses)
responses_t <- t(responses) #so that melt correctly picks up to and from
responses_m <- melt(responses_t) 
names(responses_m) <- c("from","to", "number")

# format as network

edges <- responses_m 
edges$to <- as.character(edges$to) 
edges$width <- (edges$number * 50)/sum(edges$number)
edges$title <- paste("<p style=\"color:black\">",edges$number,"</p>")
edges <- edges[edges$number > 0,]

# add in node colors, names 
nodes$group <- nodes$id 
nodes$label <- nodes$id 
nodes$title <- paste("<p style=\"color: black\">",totals$sum,"</p>")

# plot library(visNetwork) 
visNetwork(nodes, edges, width = "100%") %>%
visPhysics( solver ='forceAtlas2Based')




```




# Create shiny app 

The first stage of creating this shiny app is just making it so that the user can select (via an input box) what word the would like to look at the network of. 

Ideally I would then also make it so the can just look at the matrix of all messages sent (or perhaps have this as a seperate part of the app for comparison purposes).

Later stages of the app should then add some additional summary measures (person specific word cloud, messages sent over time, messages sent over time containing a particular word, etc). 


```{r}

## Setup

# create names
nodes <- data.frame(select(tmp, sender) %>% distinct()) 
names(nodes) <- "id"

# add in node colors, names 
nodes$group <- nodes$id 
nodes$label <- nodes$id 
nodes$title <- paste("<p style=\"color: black\">",totals$sum,"</p>")




require(shiny)
require(visNetwork)

server <- function(input, output) {
  output$network <- renderVisNetwork({
 
    # create number of messages sent for node size
    word <- "sex"
    
    totals <- select(tmp, sender, message) %>%
      mutate(ind = ifelse(grepl(input$word, tmp$message), 1, 0)) %>% 
      group_by(sender) %>% 
      summarise(sum = sum(ind)) 
    
    nodes$size <- pmax((totals$sum *100)/sum(totals$sum), 75/sum(totals$sum))
    
    # create response matrix
    responses <- response_matrix_word(tmp, 1, word = input$word) 
    responses <-as.data.frame(responses)
    responses_t <- t(responses) #so that melt correctly picks up to and from
    responses_m <- melt(responses_t) 
    names(responses_m) <- c("from","to", "number")
    
    # format as network edges
    edges <- responses_m 
    edges$to <- as.character(edges$to) 
    edges$width <- (edges$number * 50)/sum(edges$number)
    edges$title <- paste("<p style=\"color:black\">",edges$number,"</p>")
    edges <- edges[edges$number > 0,]

    

    # render network 
    visNetwork(nodes, edges) %>%
      visPhysics( solver ='forceAtlas2Based')
  })
}

ui <- fluidPage(
  
    # create user input word box 
    textInput("word", "Word", value = "hi"),

    # render output
    visNetworkOutput("network")
)

shinyApp(ui = ui, server = server)



```


# Create an app that takes a whatsapp file as input 

This is the first stage of creating the end user shiny application. It needs to be able to load any whatsapp file and produce basic analysis like the network above. 

In the first instance I'm just going to get it to load a file, format as a data.frame, and then print the first 10 rows of that data.frame. 



# currently built shiny app

Notes: I am concerned that this actually depends on the value of tmp in the other data (rather than what is loaded).

Going to test this by changing to tmp1. All still seems to work

```{r}
library(tidyverse)
library(shiny)
library(visNetwork)




ui <- fluidPage(
  sidebarLayout(
    sidebarPanel(
      fileInput("file1", "Choose CSV File",
        accept = c(
          "text/csv",
          "text/comma-separated-values,text/plain",
          ".csv")
        ),
      tags$hr(),
      checkboxInput("header", "Header", TRUE),    
      
      # create user input word box 
      textInput("word", "Word", value = "hi")

   
    ),
    mainPanel(
       
      # render output
      visNetworkOutput("network")
      
      
    )
  )
)


server <- function(input, output) {

    # Create Network  
    output$network <- renderVisNetwork({
    
    
    # input$file1 will be NULL initially. After the user selects
    # and uploads a file, it will be a data frame
    inFile <- input$file1

    if (is.null(inFile))
      return(NULL)

    loaded_chat <- read.table(inFile$datapath,  
                                fill=TRUE, header=input$header, quote="", sep="\n", encoding="UTF-8")
    names(loaded_chat) <- "string"
     
    # format the data and split into different columns
    regx <- "(\\d+/\\d+/\\d+),\\s+(\\d+:\\d+:\\d+ [A|P]M):\\s+(\\w+\\s*\\w+):\\s+(.*)"
    tmp <- loaded_chat %>%
         tidyr::extract(string, c("date", "time", "sender", "message"), regx, remove=FALSE)
     
     tmp <- filter(tmp, !is.na(sender))
     
    # create nodes list
    nodes <- data.frame(select(tmp, sender) %>% distinct()) 
    names(nodes) <- "id"

    # add in node colors, names 
    nodes$group <- nodes$id 
    nodes$label <- nodes$id

    #create number of messages sent for node size
    totals <- select(tmp, sender, message) %>%
      mutate(ind = ifelse(grepl(input$word, message), 1, 0)) %>%
      group_by(sender) %>%
      summarise(total_messages = sum(ind))

  
    nodes <- left_join(nodes, totals, by=c("id"="sender"))
    nodes$size <- pmax((nodes$total_messages *100)/sum(nodes$total_messages), 75/sum(nodes$total_messages))
    nodes$title <- paste("<p style=\"color: black\">",nodes$total_messages,"</p>")
    

    # create response matrix
    responses <- response_matrix_word(tmp, 1, word = input$word)
    responses <-as.data.frame(responses)
    responses_t <- t(responses) #so that melt correctly picks up to and from
    responses_m <- melt(responses_t)
    names(responses_m) <- c("from","to", "number")
    
    
    # format as network edges
    edges <- responses_m 
    edges$to <- as.character(edges$to) 
    edges$width <- (edges$number * 50)/sum(edges$number)
    edges$title <- paste("<p style=\"color:black\">",edges$number,"</p>")
    edges <- edges[edges$number > 0,]

    # render network 
    visNetwork(nodes, edges) %>%
      visPhysics( solver ='forceAtlas2Based')
  })
  
  
}

shinyApp(ui, server)



```


# get it working pre shiny app

```{r}
library(data.table)
library(tidyr)
    
    #chat <- fread("C:/Users/rober/Desktop/text.csv", blank.lines.skip = TRUE)
    tmp1 <- read.table("C:/Users/rober/Desktop/chat2.txt",  fill=TRUE, header=TRUE, quote="", sep="\n", encoding="UTF-8")
    names(tmp1) <- "string"

    # format the data and split into different columns
    regx <- "(\\d+/\\d+/\\d+),\\s+(\\d+:\\d+:\\d+ [A|P]M):\\s+(\\w+\\s*\\w+):\\s+(.*)"
    tmp1 <- tmp1 %>%
        tidyr::extract(string, c("date", "time", "sender", "message"), regx, remove=FALSE)


    
    tmp1 <- filter(tmp1, !is.na(sender))
    
    # create nodes list
    nodes <- data.frame(select(tmp1, sender) %>% distinct()) 
    names(nodes) <- "id"

    # add in node colors, names 
    nodes$group <- nodes$id 
    nodes$label <- nodes$id
    
    # create number of messages sent for node size
    word = "hi"
    
    totals <- select(tmp1, sender, message) %>%
      mutate(ind = ifelse(grepl(word, tmp1$message), 1, 0)) %>% 
      group_by(sender) %>% 
      summarise(sum = sum(ind)) 
    
    nodes <- left_join(nodes, totals, by=c("id"="sender"))
    nodes$size <- pmax((nodes$sum *100)/sum(nodes$sum), 75/sum(nodes$sum))
    nodes$title <- paste("<p style=\"color: black\">",nodes$sum,"</p>")
    
    # create response matrix
    responses <- response_matrix_word(tmp1, 1, word = word) 
    responses <-as.data.frame(responses)
    responses_t <- t(responses) #so that melt correctly picks up to and from
    responses_m <- melt(responses_t) 
    names(responses_m) <- c("from","to", "number")
    
    # format as network edges
    edges <- responses_m 
    edges$to <- as.character(edges$to) 
    edges$width <- (edges$number * 50)/sum(edges$number)
    edges$title <- paste("<p style=\"color:black\">",edges$number,"</p>")
    edges <- edges[edges$number > 0,]

    # render network 
    visNetwork(nodes, edges) %>%
    visPhysics( solver ='forceAtlas2Based')
    
totals
edges %>% group_by(from) %>% summarise(n=sum(number))
responses_m   

```



# Table version (rather than network) 

Useful for testing out code

```{r}
## Only run examples in interactive R sessions
if (interactive()) {

ui <- fluidPage(
  sidebarLayout(
    sidebarPanel(
      fileInput("file1", "Choose CSV File",
        accept = c(
          "text/csv",
          "text/comma-separated-values,text/plain",
          ".csv",
          ".txt")
        ),
      tags$hr(),
      checkboxInput("header", "Header", TRUE),
      
      # create user input word box 
      textInput("word", "Word", value = "hi")
      
    ),
    mainPanel(
      tableOutput("contents")
    )
  )
)

server <- function(input, output) {
  output$contents <- renderTable({
    # input$file1 will be NULL initially. After the user selects
    # and uploads a file, it will be a data frame with 'name',
    # 'size', 'type', and 'datapath' columns. The 'datapath'
    # column will contain the local filenames where the data can
    # be found.
    inFile <- input$file1

    if (is.null(inFile))
      return(NULL)

      loaded_chat <- read.table(inFile$datapath,  fill=TRUE, header=input$header, quote="", sep="\n", encoding="UTF-8")
      names(loaded_chat) <- "string"
      loaded_chat
     
    # format the data and split into different columns
     regx <- "(\\d+/\\d+/\\d+),\\s+(\\d+:\\d+:\\d+ [A|P]M):\\s+(\\w+\\s*\\w+):\\s+(.*)"
     tmp1 <- loaded_chat %>%
         tidyr::extract(string, c("date", "time", "sender", "message"), regx, remove=FALSE)
     
     tmp1 <- filter(tmp1, !is.na(sender))
     
    # create nodes list
    nodes <- data.frame(select(tmp1, sender) %>% distinct()) 
    names(nodes) <- "id"

    # add in node colors, names 
    nodes$group <- nodes$id 
    nodes$label <- nodes$id

    #create number of messages sent for node size
    totals <- select(tmp1, sender, message) %>%
      mutate(ind = ifelse(grepl(input$word, message), 1, 0)) %>%
      group_by(sender) %>%
      summarise(sum = sum(ind))

  
    nodes$size <- pmax((totals$sum *100)/sum(totals$sum), 75/sum(totals$sum))
    nodes$title <- paste("<p style=\"color: black\">",totals$sum,"</p>")


    # create response matrix
    responses <- response_matrix_word(tmp1, 1, word = input$word)
    responses <-as.data.frame(responses)
    responses_t <- t(responses) #so that melt correctly picks up to and from
    responses_m <- melt(responses_t)
    names(responses_m) <- c("from","to", "number")

    responses_m
    
  })
}

shinyApp(ui, server)
}

```





# Network comparison app 



# Network comparison app 


# Write the function that renders the network 

```{r}
library(reshape2)

create_network_whatsapp <- function(file, word){
    # load chat  
    loaded_chat <- read.table(file,  
                                fill=TRUE, header=TRUE, quote="", sep="\n", encoding="UTF-8")
    names(loaded_chat) <- "string"
     
    # format the data and split into different columns
    regx <- "(\\d+/\\d+/\\d+),\\s+(\\d+:\\d+:\\d+ [A|P]M):\\s+(\\w+\\s*\\w+):\\s+(.*)"
    tmp <- loaded_chat %>%
         tidyr::extract(string, c("date", "time", "sender", "message"), regx, remove=FALSE)
     
     tmp <- filter(tmp, !is.na(sender))
     
    # create nodes list
    nodes <- data.frame(select(tmp, sender) %>% distinct()) 
    names(nodes) <- "id"

    # add in node colors, names 
    nodes$group <- nodes$id 
    nodes$label <- nodes$id

    #create number of messages sent for node size
    totals <- select(tmp, sender, message) %>%
      mutate(ind = ifelse(grepl(word, message), 1, 0)) %>%
      group_by(sender) %>%
      summarise(total_messages = sum(ind))

  
    nodes <- left_join(nodes, totals, by=c("id"="sender"))
    nodes$size <- pmax((nodes$total_messages *100)/sum(nodes$total_messages), 75/sum(nodes$total_messages))
    nodes$title <- paste("<p style=\"color: black\">",nodes$total_messages,"</p>")
    

    # create response matrix
    responses <- response_matrix_word(tmp, 1, word = word)
    responses <-as.data.frame(responses)
    responses_t <- t(responses) #so that melt correctly picks up to and from
    responses_m <- melt(responses_t)
    names(responses_m) <- c("from","to", "number")
    
    
    # format as network edges
    edges <- responses_m 
    edges$to <- as.character(edges$to) 
    edges$width <- (edges$number * 50)/sum(edges$number)
    edges$title <- paste("<p style=\"color:black\">",edges$number,"</p>")
    edges <- edges[edges$number > 0,]

    # render network 
    visNetwork(nodes, edges) %>%
      visPhysics( solver ='forceAtlas2Based')
  
  
  
  
}

create_network_whatsapp(file = "C:/Users/rober/Desktop/chat.txt", word = "hi")


```



# Use function to write cleaner shiny app 


```{r}
library(tidyverse)
library(shiny)
library(visNetwork)
library(shinythemes)



ui <- fluidPage(theme = shinytheme("cosmo"),

fluidRow(

    column(6,
      # render first network
      visNetworkOutput("network_1")
      
    ),
    
    column(6,
      # render first network
      visNetworkOutput("network_2")
      
    )
  ),


fluidRow(
    column(4,
      
      # file input 1
      fileInput("file_1", "Choose txt File 1",
        accept = c(
          "text/csv",
          "text/comma-separated-values,text/plain",
          ".csv",
          ".txt")
        ),
      tags$hr(),
   
      
      # create user input word box 
      textInput("word_1", "Word for first network", value = "hi ")

    ), 
    column(4),
    column(4,
      # file input 2
      fileInput("file_2", "Choose txt File 2",
      accept = c(
        "text/csv",
        "text/comma-separated-values,text/plain",
        ".csv",
        ".txt")),
      
      # create user input word box 
      textInput("word_2", "Word for second network", value = "hi ")
      )
    )
)



server <- function(input, output) {

    # Create Network 1
    output$network_1 <- renderVisNetwork({
    
    
    # input$file1 will be NULL initially. After the user selects
    # and uploads a file, it will be a data frame
    inFile_1 <- input$file_1

    if (is.null(inFile_1))
      return(NULL)
    
    create_network_whatsapp(inFile_1$datapath, input$word_1)

  })
  
      # Create Network 2
    output$network_2 <- renderVisNetwork({
    
    
    # input$file1 will be NULL initially. After the user selects
    # and uploads a file, it will be a data frame
    inFile_2 <- input$file_2

    if (is.null(inFile_2))
      return(NULL)
    
    create_network_whatsapp(inFile_2$datapath, input$word_2)

  })  
    
  
}

shinyApp(ui, server)



```
