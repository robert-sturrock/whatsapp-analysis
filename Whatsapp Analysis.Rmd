---
title: "R Whatsapp Analysis"
output: html_notebook
---

This code sets out how to upload and then analyse Whatsapp text data using both charts and networks.

```{r}

library("RCurl")
library("data.table")

#tab = read.delim(getURL("https://raw.githubusercontent.com/robert-sturrock/whatsapp-analysis/master/chat.txt"))
#write.table(tab, file="text.csv",sep=",",col.names=FALSE,row.names=FALSE)


tab = read.delim("C:/Users/rober/Desktop/chat.txt")
write.table(tab, file="C:/Users/rober/Desktop/text.csv",sep=",",col.names=FALSE,row.names=FALSE)

chat <- fread("C:/Users/rober/Desktop/text.csv", blank.lines.skip = TRUE)
names(chat) <- "string"

```

Now we need to look at the data and format it approperiately 

```{r}
head(chat)

```

So we can see we have a date, time, sender, and message. 

The first obvious issue here is that one of the senders names has been messed up. We can fix this using the regex commands in R 

```{r}

chat$string <- gsub("â.ª.*:", "Debbie Blair:", chat$string )
head(chat$string)




```

Now that we have made that correction we need to split the string of text into the individual components identified above: 

```{r}
library(tidyverse)

regx <- "(\\d+/\\d+/\\d+),\\s+(\\d+:\\d+:\\d+ [A|P]M):\\s+(\\w+\\s+\\w+):\\s+(.*)"

tmp <- chat %>% 
    extract(string, c("date", "time", "sender", "message"), regx, remove=FALSE)




```

We now have our desired variables. Lets build some basic functionality like search

```{r}

#regular expression search
grep("sex", tmp$message, value=TRUE)


#function that returns other columns of the data as well
text_search <- function(text, df){
  tmp <- df
  tmp_index <- grep(text, tmp$message)
  tmp[c(tmp_index),c("sender", "message")]
}

text_search("sex", tmp)

#function to search around a specific instance (message before and after)


conv_search <- function(text, df){ 
  tmp <- df
  tmp_index <- grep(text, tmp$message)
  
  #return lines
  index <- tmp_index
  
  function(instance, num_lines){
    if (num_lines %% 2 !=0){"error, needs even number"} else {
    
    instance <- index[instance]
    start <- instance - num_lines/2
    end   <- instance + num_lines/2  
    tmp[start:end, c("sender", "message")]
    } 
  }
  
  
}

sex_search <- conv_search("sex", tmp)
sex_search(2,6)

library(wordcloud)


```



Great. So we built some functions that make it easy to search text. 

But searching isn't really the best way to get data about what people talked about. Charts on the other hand are awesome. 

I start by building a simple frequency chart of how often a given work was said


```{r}

# Create a single block of text with all the words

test <- unlist(tmp$message)
test <- paste(test, sep="",collapse ="")

# load required packages

library(tm)
library(dplyr)
library(xtable)

docs <- Corpus(VectorSource(test)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(tolower)  %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stripWhitespace) %>%
  tm_map(PlainTextDocument)

tdm <- TermDocumentMatrix(docs) %>%
  as.matrix()

tdm <- as.matrix(tdm[,1])
tdm <- as.matrix(tdm[order(tdm, decreasing = TRUE),])
tdm <- as.matrix(tdm[10:17546,])
tdm <- tdm[order(tdm, decreasing = TRUE),]



wordcloud(names(tdm), tdm, min.freq = 35, scale=c(5, .2), random.order = FALSE, random.color = FALSE, colors= c("indianred1","indianred2","indianred3","indianred"))


```

